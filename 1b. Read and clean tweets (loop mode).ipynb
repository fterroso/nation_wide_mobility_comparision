{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fterroso/python/lib/python3.6/site-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
      "  \"\"\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from geopandas.tools import sjoin\n",
    "import numpy as np\n",
    "from shapely.geometry import Point, LineString\n",
    "from tqdm import tqdm_notebook\n",
    "import math\n",
    "from geoalchemy2 import Geometry, WKTElement\n",
    "from sqlalchemy import *\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/fterroso/data/'\n",
    "tweets_path = '/home/fterroso/projects/twitter-crawler/streaming_tweets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "#e_date = datetime.datetime.now()\n",
    "e_date =  datetime.datetime.strptime('2020-08-01', '%Y-%m-%d')\n",
    "i_date = datetime.datetime.strptime('2020-07-22', '%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def read_tweets_from_file_fn(f):\n",
    "    geo_point_tweets = []\n",
    "    geo_poly_tweets_info = []\n",
    "    geo_poly_tweets_geom = []\n",
    "\n",
    "    #for file in tqdm_notebook(filenames, desc=\"Reading files\"):\n",
    "    #    filepath= dataPath + file\n",
    "    with open(f) as fp:\n",
    "        line = fp.readline()\n",
    "        while line:\n",
    "            tw = json.loads(line)\n",
    "            \n",
    "            #point-based coordinates\n",
    "            if tw['coordinates']:\n",
    "                lon = tw['coordinates']['coordinates'][0]\n",
    "                lat = tw['coordinates']['coordinates'][1]\n",
    "                if (lat > 35.86) & (lat < 43.74) & (lon > -9.57) &  (lon < 4.39):\n",
    "                    geo_point_tweets.append((tw['id'], tw['user']['id'],tw['text'], tw['created_at'], lon, lat))\n",
    "                    #geo_tag_tweets.append(tweet)\n",
    "                    \n",
    "            #polygon-based coordinates        \n",
    "            elif tw['place']['country_code']=='ES':\n",
    "                \n",
    "                geo_poly_tweets_info.append((tw['id'], tw['user']['id'],\n",
    "                                        tw['text'], \n",
    "                                        tw['created_at'], \n",
    "                                        tw['place']['full_name'], \n",
    "                                        tw['place']['place_type']))\n",
    "                \n",
    "                geo_poly_tweets_geom.append(tw['place']['bounding_box'])\n",
    "            \n",
    "            line = fp.readline()\n",
    "    \n",
    "    return geo_point_tweets, geo_poly_tweets_info, geo_poly_tweets_geom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def search_for_files(listOfFactorNames, path):\n",
    "    for f in os.listdir(path):\n",
    "        for factor in listOfFactorNames:\n",
    "            if factor in f:\n",
    "                yield f\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_point_tweets_fn(p_tweets):\n",
    "    df = pd.DataFrame.from_records(p_tweets, columns='tw_id user_id text timestamp lon lat'.split())\n",
    "    gdf = gpd.GeoDataFrame(df, crs={'init': 'epsg:4326'}, geometry=gpd.points_from_xy(df.lon, df.lat))\n",
    "    \n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Polygon\n",
    "\n",
    "def convert_polygon_tweets_fn(poly_tweets_info, poly_tweets_geom):\n",
    "    poly_geom = []\n",
    "    \n",
    "    #convert bounding box to shapely polygons\n",
    "    for bbox in poly_tweets_geom:\n",
    "\n",
    "        coords_list = bbox['coordinates'][0]\n",
    "        coords_tuple = [tuple(c) for c in coords_list]\n",
    "        polygon = Polygon(coords_tuple)\n",
    "        #print(coords_list)\n",
    "        poly_geom.append(polygon)\n",
    "\n",
    "    df = pd.DataFrame.from_records(poly_tweets_info, columns='tw_id user_id text timestamp place_name place_type'.split())\n",
    "    gdf = gpd.GeoDataFrame(df, crs={'init': 'epsg:4326'}, geometry=poly_geom)\n",
    "\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, timedelta\n",
    "\n",
    "\n",
    "def convert_tweets_to_geodf_fn():\n",
    "\n",
    "    delta = e_date - i_date       # as timedelta\n",
    "\n",
    "    print(\"Processing days:\")\n",
    "    target_days = []\n",
    "    for i in range(delta.days + 1):\n",
    "        day = i_date + timedelta(days=i)\n",
    "        day_str= day.strftime('%d-%m-%Y')\n",
    "        #print(day_str)\n",
    "        files = list(search_for_files([day_str], tweets_path))\n",
    "        #print(files)\n",
    "        if len(files)>0:\n",
    "            print(day_str, end=', ')\n",
    "            point_tweets = []\n",
    "            poly_tweets_info= []\n",
    "            poly_tweets_bbox= []\n",
    "            for f in files:\n",
    "                point_tweets_f, poly_tweets_info_f, poly_tweets_bbox_f = read_tweets_from_file_fn(tweets_path + f)\n",
    "                point_tweets = point_tweets + point_tweets_f\n",
    "                poly_tweets_info = poly_tweets_info + poly_tweets_info_f\n",
    "                poly_tweets_bbox = poly_tweets_bbox + poly_tweets_bbox_f\n",
    "\n",
    "            poly_tweets_gdf = convert_polygon_tweets_fn(poly_tweets_info, poly_tweets_bbox)\n",
    "            point_tweets_gdf = convert_point_tweets_fn(point_tweets)\n",
    "\n",
    "            poly_tweets_gdf.to_file(\"data/poly_tweets_{}.geojson\".format(day_str), driver='GeoJSON', encoding='utf-8')\n",
    "            point_tweets_gdf.to_file(\"data/point_tweets_{}.geojson\".format(day_str), driver='GeoJSON', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing days:\n",
      "22-07-2020, 23-07-2020, 24-07-2020, 25-07-2020, 26-07-2020, 27-07-2020, 28-07-2020, 29-07-2020, 30-07-2020, 31-07-2020, 01-08-2020, "
     ]
    }
   ],
   "source": [
    "convert_tweets_to_geodf_fn()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
